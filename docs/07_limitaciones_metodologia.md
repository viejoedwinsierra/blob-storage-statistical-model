---
üè† [Inicio](../README.md)

‚¨ÖÔ∏è [Anterior](06_preguntas_analiticas.md)

‚û°Ô∏è [Siguiente](08_validaciones_calidad.md)

---

# 7. Limitaciones y consideraciones metodol√≥gicas

## 7.1 Naturaleza sint√©tica del dataset

El modelo se basa en simulaci√≥n controlada y no en datos productivos reales.  
Esto implica:

- No se capturan patrones espec√≠ficos de negocio.
- No se modelan dependencias organizacionales reales.
- No se consideran restricciones regulatorias o pol√≠ticas de retenci√≥n.

Sin embargo, la simulaci√≥n garantiza control del fen√≥meno y reproducibilidad experimental.

---

## 7.2 Supuesto de independencia diaria

El modelo asume que:

- Los d√≠as son independientes entre s√≠.
- El estado del sistema \(I_t\) sigue un proceso Bernoulli sin memoria.

En entornos reales, los incidentes pueden presentar:

- Persistencia temporal.
- Correlaci√≥n entre d√≠as consecutivos.
- Efectos de recuperaci√≥n gradual.

Extensi√≥n posible:
Modelar \(I_t\) como un proceso de Markov o incluir autocorrelaci√≥n.

---

## 7.3 Supuesto de independencia entre blobs

Se asume que cada blob generado en un d√≠a tiene probabilidad independiente \(p_t\) de ser duplicado.

En sistemas reales pueden existir:

- Dependencias por lote.
- Reintentos masivos simult√°neos.
- Eventos correlacionados intra-d√≠a.

Este supuesto simplifica el an√°lisis pero puede subestimar la varianza real.

---

## 7.4 Posible sobredispersi√≥n

El modelo Poisson asume:

\[
Var(X_t) = E[X_t]
\]

En sistemas distribuidos reales puede observarse:

\[
Var(X_t) > E[X_t]
\]

debido a:

- Burst patterns.
- Congesti√≥n de red.
- Eventos coordinados.

Mitigaci√≥n:
Uso de modelo Binomial Negativa si se detecta sobredispersi√≥n.

---

## 7.5 Sensibilidad al factor k

El par√°metro k controla la magnitud de los picos.

- Valores bajos pueden subestimar impacto.
- Valores altos pueden sobreestimar efectos.

Se recomienda an√°lisis de sensibilidad variando k ‚àà [2,8].

---

## 7.6 Ambig√ºedad entre duplicaci√≥n l√≥gica y f√≠sica

El modelo asume que:

- Duplicaci√≥n por contenido implica redundancia f√≠sica.

En sistemas reales pueden existir:

- Compresi√≥n.
- Deduplicaci√≥n autom√°tica en backend.
- Versionado interno.

Esto puede reducir impacto real en almacenamiento f√≠sico.

---

## 7.7 Escalabilidad y costos computacionales

Aunque el modelo es conceptualmente escalable a terabytes:

- El c√°lculo de hash completo puede ser costoso.
- El procesamiento masivo requiere arquitectura distribuida.
- El acceso a metadatos puede tener latencia significativa.

Implementaci√≥n real requerir√≠a:

- Procesamiento incremental.
- Uso de particiones.
- Agregaci√≥n distribuida (Spark / MapReduce).

---

## 7.8 Desbalance entre clases (d√≠as normales vs incidentes)

Si \(p_{incident}\) es bajo (ej. 5%):

- La mayor√≠a de observaciones ser√°n d√≠as normales.
- Puede generarse desbalance en modelos predictivos.

Mitigaci√≥n:

- Estratificaci√≥n.
- M√©tricas robustas (AUC, recall en clase minoritaria).
- Simulaci√≥n de escenarios adicionales.

---

## 7.9 Limitaciones temporales

El modelo opera en granularidad diaria.

No captura:

- Picos horarios.
- Micro-burst intra-minuto.
- Efectos de ventana m√≥vil.

Extensi√≥n futura:
Modelamiento por hora o minuto.

---

## 7.10 Consideraciones de interpretaci√≥n

Los resultados del modelo deben interpretarse como:

- Evaluaci√≥n estructural del riesgo.
- Estimaci√≥n probabil√≠stica del impacto.
- Herramienta de an√°lisis comparativo.

No deben considerarse como predicci√≥n exacta del comportamiento productivo.

---

## 7.11 Conclusi√≥n metodol√≥gica

El modelo prioriza:

- Claridad estructural.
- Reproducibilidad.
- Escalabilidad conceptual.
- Capacidad de extensi√≥n.

Las simplificaciones realizadas permiten:

- Enfoque anal√≠tico controlado.
- Evaluaci√≥n de hip√≥tesis contrastables.
- Comparaci√≥n de escenarios.

La robustez del enfoque radica en su capacidad de adaptarse a datos reales mediante calibraci√≥n de par√°metros y validaci√≥n emp√≠rica.
