---
üè† [Inicio](../README.md)

‚¨ÖÔ∏è [Anterior](03_estructura_dataset.md)

‚û°Ô∏è [Siguiente](05_modelamiento_estadistico.md)

---

# 4. Par√°metros de simulaci√≥n

## 4.1 Prop√≥sito de la simulaci√≥n

La simulaci√≥n permite generar un dataset sint√©tico que reproduzca el comportamiento del almacenamiento (Blob Storage) bajo dos reg√≠menes operativos:

1) **Operaci√≥n normal**: el volumen de blobs crece proporcionalmente al volumen transaccional.  
2) **Operaci√≥n degradada (incidente)**: por timeouts y reintentos, el sistema genera **duplicados por contenido** (mismo `content_hash`), incrementando de forma abrupta el n√∫mero de blobs y el volumen total almacenado.

El resultado de la simulaci√≥n debe producir las tablas definidas en `03_estructura_dataset.md`:

- `blob_inventory` (nivel archivo/blob)
- `events_daily` (agregaci√≥n diaria)

---

## 4.2 Horizonte y tama√±o del experimento

### 4.2.1 Horizonte temporal
- **T = d√≠as = 180**
- Interpretaci√≥n: se simula un per√≠odo continuo (por ejemplo, 6 meses) para observar efectos acumulativos y estacionalidad simple.

### 4.2.2 Tama√±o muestral
- **N = 10,000**
- Uso: tama√±o de poblaci√≥n base para:
  - simulaci√≥n Monte Carlo (N corridas), o
  - universo de transacciones/identificadores si se quiere modelar colisiones/reintentos sobre un set finito.

> Recomendaci√≥n pr√°ctica:
> - Si est√°s haciendo **una sola l√≠nea temporal de 180 d√≠as**, N puede interpretarse como el tama√±o del ‚Äúpool‚Äù de claves/hashes potenciales.
> - Si est√°s haciendo **simulaci√≥n Monte Carlo**, N representa el n√∫mero de ejecuciones de la simulaci√≥n para estimar intervalos y distribuciones (medias, percentiles).

---

## 4.3 Par√°metros operacionales del sistema

### 4.3.1 Œª (lambda) ‚Äî tasa media diaria de transacciones
- **Œª = 1000 transacciones/d√≠a**
- Uso: controla el volumen esperado de blobs en operaci√≥n normal.
- Modelo:
  - En d√≠a normal:  
    \[
    X_t \sim \text{Poisson}(\lambda)
    \]
- Interpretaci√≥n: el sistema tiene una tasa media estable con variabilidad natural (Poisson).

**Lectura de negocio**: si Œª sube, el storage crece linealmente incluso sin incidentes.

---

### 4.3.2 k ‚Äî factor de amplificaci√≥n durante incidentes
- **k = 3**
- Uso: representa multiplicaci√≥n del volumen por reintentos (timeouts ‚Üí reenv√≠os ‚Üí duplicados).
- Modelo:
  - En d√≠a con falla:  
    \[
    X_t \sim \text{Poisson}(k\lambda)
    \]
- Interpretaci√≥n: durante un incidente, la plataforma efectivamente procesa (o intenta procesar) ~k veces la carga normal.

**Lectura t√©cnica**: k agrega ‚Äúburst‚Äù de escritura y explica picos de volumen, aun sin aumento real de usuarios.

---

## 4.4 Par√°metros de confiabilidad (estado del d√≠a)

### 4.4.1 Probabilidad de incidente por d√≠a
- En el documento aparecen:
  - **p_fail = 0.10**
  - y tambi√©n ‚Äú**5% d√≠as con falla**‚Äù

‚ö†Ô∏è Debe quedar un **solo valor** para consistencia.  
Recomendaci√≥n: define:

- **p_incident = 0.05** (si el supuesto es 5% d√≠as con falla)

y deja **p_fail = p_incident**.

#### Variable de estado del d√≠a
\[
I_t \sim \text{Bernoulli}(p_{\text{incident}})
\]
- Si \(I_t = 0\): d√≠a normal  
- Si \(I_t = 1\): d√≠a con incidente

---

## 4.5 Par√°metros de duplicaci√≥n por contenido

### 4.5.1 p_ok y p_fail ‚Äî tasa de duplicaci√≥n seg√∫n el estado

- **p_ok = 0.02**  
  - En d√≠as normales, se permite una peque√±a tasa de duplicaci√≥n (ej: reintentos puntuales, reprocesos marginales, ‚Äúat least once delivery‚Äù).
- **p_fail = 0.10**  
  - En d√≠as con incidente, la duplicaci√≥n aumenta por reintentos sistem√°ticos.

#### Definici√≥n del par√°metro efectivo diario
\[
p_t =
\begin{cases}
p_{ok} & \text{si } I_t = 0 \\
p_{fail} & \text{si } I_t = 1
\end{cases}
\]

### 4.5.2 Modelo de duplicados por d√≠a
Dado el total de blobs creados en el d√≠a \(X_t\), los duplicados (por contenido) se modelan como:

\[
D_t \sim \text{Binomial}(X_t, p_t)
\]

Donde:
- \(D_t\) = cantidad de blobs cuyo contenido **replica** contenido ya existente (hash repetido)
- \(X_t\) = total de blobs creados ese d√≠a
- \(p_t\) = probabilidad de que un blob sea duplicado (dependiendo del estado)

---

## 4.6 Relaci√≥n con TPS (Transacciones por segundo)

Para enriquecer `events_daily.TPS_t`, se puede estimar:

\[
TPS_t = \frac{X_t}{86400}
\]

> Ajuste opcional (mejor realismo):
> durante incidentes, TPS observado puede **aumentar** por reintentos aunque la demanda real no crezca.  
> Esto se modela naturalmente porque \(X_t\) crece por k.

---

## 4.7 Tama√±o de archivo y volumen diario

Sea:
- **S = 1MB por blob** (o en bytes: ~1,048,576)

Volumen diario:

\[
V_t = X_t \cdot S
\]

Volumen acumulado:

\[
V_{1:T} = \sum_{t=1}^{T} V_t
\]

---

## 4.8 Resumen de par√°metros (tabla)

| Par√°metro | Valor | Unidad | Significado | Impacto principal |
|----------|------:|--------|-------------|------------------|
| T (d√≠as) | 180 | d√≠as | Horizonte de simulaci√≥n | Efecto acumulado |
| Œª | 1000 | tx/d√≠a | Tasa media normal | Crecimiento base |
| k | 3 | factor | Amplificaci√≥n en incidentes | Picos + duplicados |
| p_incident | 0.05 (o 0.10) | prob/d√≠a | Frecuencia de d√≠as con falla | Frecuencia de picos |
| p_ok | 0.02 | prob/blob | Duplicaci√≥n normal | Ruido de base |
| p_fail | 0.10 | prob/blob | Duplicaci√≥n en falla | Duplicados masivos |
| S | 1MB | bytes/blob | Tama√±o promedio archivo | Costos storage |

---

## 4.9 Escenarios de simulaci√≥n recomendados (para an√°lisis comparativo)

Para que el an√°lisis sea m√°s robusto, se sugieren al menos estos escenarios:

1) **Baseline**: p_incident bajo (1‚Äì2%), k moderado (2‚Äì3)  
2) **Incidentes frecuentes**: p_incident alto (10%), k moderado  
3) **Incidente severo**: p_incident medio (5%), k alto (5‚Äì8)  
4) **Duplicaci√≥n alta sin aumentar volumen**: k ~ 1 pero p_fail alto (simula reescrituras/reprocesos)

Esto permite comparar sensibilidad del crecimiento y costo.

---

## 4.10 Distribuciones principales (definici√≥n final)

### Estado del d√≠a
\[
I_t \sim \text{Bernoulli}(p_{\text{incident}})
\]

### Blobs generados
\[
X_t \sim
\begin{cases}
\text{Poisson}(\lambda) & I_t = 0 \\
\text{Poisson}(k\lambda) & I_t = 1
\end{cases}
\]

### Duplicados por contenido
\[
D_t \sim \text{Binomial}(X_t, p_t)
\]

### Tasa de duplicaci√≥n observada
\[
duplicate\_rate_t = \frac{D_t}{X_t}
\]

---

## 4.11 Notas de consistencia (importante)

- Si se mantiene ‚Äú**5% d√≠as con falla**‚Äù, entonces:
  - usar **p_incident = 0.05** (y retirar p_fail como probabilidad diaria)
- Reservar **p_fail** exclusivamente para ‚Äúprobabilidad de duplicaci√≥n por blob‚Äù en d√≠a con incidente.

Esto evita ambig√ºedad y hace el modelo reproducible.

---
