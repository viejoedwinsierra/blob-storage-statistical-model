---
 [Inicio](../README.md)

猬锔 [Anterior](07_limitaciones_metodologia.md)

★ [Siguiente](09_modelo_causal_fallas.md)

---

# 8. Validaciones de calidad

## 8.1 Marco conceptual de calidad de datos

La calidad del dataset se eval煤a bajo cuatro dimensiones fundamentales:

1. **Integridad estructural**
2. **Consistencia l贸gica**
3. **Coherencia estad铆stica**
4. **Reproducibilidad del proceso generativo**

Estas dimensiones garantizan que el modelo estad铆stico opere sobre datos v谩lidos y coherentes.

---

## 8.2 Validaciones estructurales (nivel blob)

Se verifican condiciones m铆nimas de integridad:

- `size_bytes >= 0`
- `content_hash` no nulo
- `blob_id` 煤nico
- `created_at <= last_modified_at`
- `path` v谩lido y consistente con la estructura jer谩rquica definida

Objetivo:
Evitar inconsistencias que comprometan el an谩lisis probabil铆stico.

---

## 8.3 Validaciones de unicidad y duplicaci贸n

Se eval煤an tres niveles de control:

### 1锔 Unicidad t茅cnica
- No deben existir duplicados exactos de `(blob_id)`.

### 2锔 Duplicaci贸n por contenido
- Identificaci贸n de grupos donde `content_hash` se repite.
- C谩lculo de cardinalidad por hash.

### 3锔 Duplicaci贸n cruzada por path
- Verificaci贸n de replicaci贸n inter-directorio.
- An谩lisis de concentraci贸n por contenedor.

Esto permite validar que la simulaci贸n produce correctamente los escenarios Tipo A, B y C definidos previamente.

---

## 8.4 Validaciones temporales

Se verifica:

- Secuencia continua de d铆as (sin saltos en T).
- Correspondencia entre `events_daily.day` y agregaci贸n de `blob_inventory.created_at`.
- Coherencia entre incident_flag y volumen observado.

Prueba clave:

\[
E[X_t | I_t=1] > E[X_t | I_t=0]
\]

Si esta condici贸n no se cumple, la simulaci贸n estar铆a mal configurada.

---

## 8.5 Validaciones estad铆sticas

Se contrasta emp铆ricamente:

1. Media vs varianza en d铆as normales:
   \[
   Var(X_t) \approx E[X_t]
   \]

2. Media vs varianza en d铆as con falla.

3. Tasa promedio observada:
   \[
   \bar{duplicate\_rate} \approx p_{ok}
   \text{ (en d铆as normales)}
   \]

4. Tasa promedio observada:
   \[
   \bar{duplicate\_rate} \approx p_{fail}
   \text{ (en d铆as con incidente)}
   \]

Estas verificaciones confirman coherencia entre par谩metros te贸ricos y datos generados.

---

## 8.6 Validaci贸n de coherencia volumenTPS

Se valida que:

\[
TPS_t = \frac{X_t}{86400}
\]

y que durante incidentes:

\[
E[TPS_t | I_t=1] > E[TPS_t | I_t=0]
\]

Esto garantiza consistencia entre modelo de conteo y m茅trica derivada.

---

## 8.7 Escalabilidad y validaci贸n en contexto Big Data

Para escenarios de mayor escala (GBTB):

- Validar que la agregaci贸n diaria pueda ejecutarse en procesamiento distribuido.
- Validar particionamiento por fecha.
- Validar que el c谩lculo de hash no introduzca sesgo sistem谩tico.
- Validar consistencia en ejecuci贸n paralela.

---

## 8.8 Conclusi贸n sobre calidad del dataset

Las validaciones implementadas aseguran:

- Integridad estructural.
- Consistencia probabil铆stica.
- Reproducibilidad experimental.
- Coherencia entre modelo te贸rico y datos simulados.

La calidad del dataset es condici贸n necesaria para que los modelos de conteo y duplicaci贸n produzcan inferencias v谩lidas.
